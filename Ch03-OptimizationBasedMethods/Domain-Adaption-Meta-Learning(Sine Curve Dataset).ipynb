{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Exercise: Domain Adaption Meta Learning\n",
    "\n",
    "For this tutorial, we will be showcasing use of Domain Adaption Meta Learning, to learn a simple curve of sinusoidal data. It's a variation of 'Model Agnostic Meta Learning', but with added prior information i.e; extra relevant information about domain is already added.\n",
    "\n",
    "Let's Begin!!!!\n",
    "\n",
    "Meta-learning algorithms optimize for the ability to learn new tasks quickly. To do so, they use data\n",
    "collected across a wide range of tasks and are evaluated based on their ability to learn new meta-test tasks.\n",
    "This process can be formalized as learning a prior over functions, and the fine-tuning process as inference under the\n",
    "learned prior. [Source, DAML paper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DAML.png\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import all libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/project09/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-0c62a3114a7f>\", line 12, in <module>\n",
      "    get_ipython().magic('matplotlib inline')\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2146, in magic\n",
      "    return self.run_line_magic(magic_name, magic_arg_s)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2067, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-107>\", line 2, in matplotlib\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/IPython/core/magics/pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2930, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 307, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 229, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1305, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/opt/anaconda3/envs/project09/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import sys\n",
    "import torch # v0.4.1\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create a simple neural network architecture, which is going to learn the sinusoidal curve.\n",
    "As mentioned above, we will be getting randomly generated data of sinusoidal curve so, we will be using this very small network, as we don't need a big one to learn a curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meta_net(x, params): \n",
    "    # main network which is suppose to learn our main objective i.e; learn sinusoidal curve family here.\n",
    "    x = F.linear(x, params[0], params[1])\n",
    "    x1 = F.relu(x)\n",
    "\n",
    "    x = F.linear(x1, params[2], params[3])\n",
    "    x2 = F.relu(x)\n",
    "\n",
    "    y = F.linear(x2, params[4], params[5])\n",
    "\n",
    "    return y, x2, x1\n",
    "\n",
    "params = [\n",
    "    torch.Tensor(32, 1).uniform_(-1., 1.).requires_grad_(),\n",
    "    torch.Tensor(32).zero_().requires_grad_(),\n",
    "\n",
    "    torch.Tensor(32, 32).uniform_(-1./math.sqrt(32), 1./math.sqrt(32)).requires_grad_(),\n",
    "    torch.Tensor(32).zero_().requires_grad_(),\n",
    "\n",
    "    torch.Tensor(1, 32).uniform_(-1./math.sqrt(32), 1./math.sqrt(32)).requires_grad_(),\n",
    "    torch.Tensor(1).zero_().requires_grad_(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Create another simple neural network architecture, for collecting and adding prior information about domain.\n",
    "As mentioned above, we will be adding a prior knowledge to our main net. Therefore, we need to create a simple adap_net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adap_net(y, x2, x1, params): \n",
    "    # the net takes forward pass from meta_net and provides efficient parameter initializations i.e;\n",
    "    # It works adapts the meta_net easily to any form of change\n",
    "    \n",
    "    x = torch.cat([y, x2, x1], dim=1)\n",
    "\n",
    "    x = F.linear(x, params[0], params[1])\n",
    "    x = F.relu(x)\n",
    "\n",
    "    x = F.linear(x, params[2], params[3])\n",
    "    x = F.relu(x)\n",
    "\n",
    "    x = F.linear(x, params[4], params[5])\n",
    "\n",
    "    return x\n",
    "\n",
    "adap_params = [\n",
    "    torch.Tensor(32, 1+32+32).uniform_(-1./math.sqrt(65), 1./math.sqrt(65)).requires_grad_(),\n",
    "    torch.Tensor(32).zero_().requires_grad_(),\n",
    "\n",
    "    torch.Tensor(32, 32).uniform_(-1./math.sqrt(32), 1./math.sqrt(32)).requires_grad_(),\n",
    "    torch.Tensor(32).zero_().requires_grad_(),\n",
    "\n",
    "    torch.Tensor(1, 32).uniform_(-1./math.sqrt(32), 1./math.sqrt(32)).requires_grad_(),\n",
    "    torch.Tensor(1).zero_().requires_grad_(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 4: set up parameters for training\n",
    "so as we are going to use inner loop vs outer loop training as mentioned in DAML paper. thus, we need to set certain parameters such as alpha, beta, learning rate, optimizer, and number of loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(params + adap_params, lr=1e-2)\n",
    "n_inner_loop = 5\n",
    "alpha = 3e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Implement Optimization Algorithm \n",
    "As mentioned in paper, this approach can learn new skill from only one video of a human. For this, it first trains to build a strong and rich prior over tasks during a meta-training phase, using both human demonstrations and teleoperated demonstrations are available.\n",
    "\n",
    "In this phase, the robot(meta_net) learns \"how to learn from humans\" using data. After the meta-training phase, the robot can acquire new skills by combining its learned prior knowledge with one video of a human performing the new skill.\n",
    "\n",
    "\n",
    "This approach consists of two phases. \n",
    "(i) In the metatraining phase, the goal will be to acquire a prior over policies(phi) using both human and robot demonstration data.\n",
    "\n",
    "(ii) Use learned prior to quickly learn to imitate new tasks with only few data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: adap_net works something similar to lstm meta learner, it provides info for main network in terms of parameters to converge faster and better. It provides new parameters after parsing through data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4713/100000 [00:36<11:21, 139.72it/s]"
     ]
    }
   ],
   "source": [
    "inner_loop_loss=[]\n",
    "outer_lopp_loss=[]\n",
    "\n",
    "# Here, T ∼ p(T ) {or minibatch of tasks} is to learn sinusoidal family curves\n",
    "\n",
    "with tqdm(total=100000, file=sys.stdout) as pbar:\n",
    "    for it in range(100000):\n",
    "        b = 0 if random.choice([True, False]) else math.pi\n",
    "        #### Randomly obtain the task 2 sinusoidal data ####\n",
    "        \n",
    "        # Sample robotic task data d_r~D_r\n",
    "        v_x = torch.rand(4, 1)*4*math.pi - 2*math.pi \n",
    "        v_y = torch.sin(v_x + b)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        new_params = params\n",
    "        for k in range(n_inner_loop):\n",
    "            # Sample Human task data d_h~D_h\n",
    "            sampled_data = torch.FloatTensor([[random.uniform(math.pi/4, math.pi/2) \n",
    "                                               if b == 0 else random.uniform(-math.pi/2, -math.pi/4)]])\n",
    "            \n",
    "            # Here, si is adap_net parameters: adap_params and theta is meta_net parameters: new_params\n",
    "            f, f2, f1 = meta_net(sampled_data, new_params) \n",
    "            h = adap_net(f, f2, f1, adap_params)\n",
    "            \n",
    "             # calculate loss\n",
    "            adap_loss = F.l1_loss(h, torch.zeros(1, 1))\n",
    "            grads = torch.autograd.grad(adap_loss, new_params, create_graph=True)\n",
    "            \n",
    "            # Compute policy parameters phi_t(new_params)\n",
    "            new_params = [(new_params[i] - alpha*grads[i]) for i in range(len(params))]\n",
    "\n",
    "            if it % 100 == 0: \n",
    "                inner_loop_loss.append(adap_loss)\n",
    "\n",
    "        v_f, _, _ = meta_net(v_x, new_params) # forward pass using learned policy parameters phi_t\n",
    "        loss = F.l1_loss(v_f, v_y) # calculate the loss of meta_net\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step() # optimize the policy parameters(theta and si)\n",
    "        pbar.update(1)\n",
    "        if it % 100 == 0: \n",
    "            outer_lopp_loss.append(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Fine-tune our main net \n",
    "Once we have obtained right parameters, we will first generate some random data points to sub-sample 5 data points, and fine-tune main 'meta_net' using loss of adap_net. \n",
    "\n",
    "When deployed, the robot can adapt to a particular task with novel objects using just a single video of a human performing the task with those objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_b = math.pi\n",
    "opt.zero_grad()\n",
    "t_params = params\n",
    "\n",
    "for k in range(n_inner_loop):\n",
    "    # sample the new task data\n",
    "    new_task_data = torch.FloatTensor([[random.uniform(math.pi/4, math.pi/2)\n",
    "                                        if t_b == 0 else random.uniform(-math.pi/2, -math.pi/4)]])\n",
    "    # forward pass through meta_net to extract the input for adap_net\n",
    "    t_f, t_f2, t_f1 = meta_net(new_task_data, t_params)\n",
    "    # extract the information from adap_net\n",
    "    t_h = adap_net(t_f, t_f2, t_f1, adap_params)\n",
    "    # calculate the loss, here we used true label as torch.zeros(1, 1), because t_b = pi\n",
    "    t_adap_loss = F.l1_loss(t_h, torch.zeros(1, 1))\n",
    "\n",
    "    grads = torch.autograd.grad(t_adap_loss, t_params, create_graph=True)\n",
    "    # learn the policy using the loss of adap_net\n",
    "    t_params = [(t_params[i] - alpha*grads[i]) for i in range(len(params))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6: Visualize outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.arange(-2*math.pi, 2*math.pi, step=0.01).unsqueeze(1)\n",
    "test_y = torch.sin(test_x + t_b)\n",
    "\n",
    "test_f, _, _ = meta_net(test_x, t_params) # use the learned parameters\n",
    "\n",
    "plt.plot(test_x.data.numpy(), test_y.data.numpy(), label='sin(x)')\n",
    "plt.plot(test_x.data.numpy(), test_f.data.numpy(), label='meta_net(x)')\n",
    "plt.legend()\n",
    "plt.savefig('daml-sine.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(inner_loop_loss,name=\"Loss Curve\"):\n",
    "    plt.plot(inner_loop_loss, label=name)\n",
    "    plt.legend()\n",
    "plot_loss(outer_lopp_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
