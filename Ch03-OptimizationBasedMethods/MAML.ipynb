{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch\n",
    "from    torch import nn\n",
    "from    torch import optim\n",
    "from    torch.nn import functional as F\n",
    "from    torch.utils.data import TensorDataset, DataLoader\n",
    "from    torch import optim\n",
    "import  numpy as np\n",
    "from    copy import deepcopy\n",
    "import  torch\n",
    "from    torch import nn\n",
    "from    torch.nn import functional as F\n",
    "import  numpy as np\n",
    "import  torch, os\n",
    "import  scipy.stats\n",
    "from    torch.utils.data import DataLoader\n",
    "from    torch.optim import lr_scheduler\n",
    "import  random, sys, pickle\n",
    "import  argparse\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import collections\n",
    "from PIL import Image\n",
    "import csv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINI ImageNet Data\n",
    "\n",
    "Download Mini ImageNet Dataset: https://drive.google.com/file/d/1HkgrkAwukzEZA0TpO7010PkAOREb2Nuk/view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniImagenet(Dataset):\n",
    "    \"\"\"\n",
    "    put mini-imagenet files as :\n",
    "    root :\n",
    "        |- images/*.jpg includes all imgeas\n",
    "        |- train.csv\n",
    "        |- test.csv\n",
    "        |- val.csv\n",
    "    NOTICE: meta-learning is different from general supervised learning, especially the concept of batch and set.\n",
    "    batch: contains several sets\n",
    "    sets: conains n_way * k_shot for meta-train set, n_way * n_query for meta-test set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, mode, batchsz, n_way, k_shot, k_query, resize, startidx=0):\n",
    "        \"\"\"\n",
    "        :param root: root path of mini-imagenet\n",
    "        :param mode: train, val or test\n",
    "        :param batchsz: batch size of sets, not batch of imgs\n",
    "        :param n_way:\n",
    "        :param k_shot:\n",
    "        :param k_query: num of qeruy imgs per class\n",
    "        :param resize: resize to\n",
    "        :param startidx: start to index label from startidx\n",
    "        \"\"\"\n",
    "\n",
    "        self.batchsz = batchsz  # batch of set, not batch of imgs\n",
    "        self.n_way = n_way  # n-way\n",
    "        self.k_shot = k_shot  # k-shot\n",
    "        self.k_query = k_query  # for evaluation\n",
    "        self.setsz = self.n_way * self.k_shot  # num of samples per set\n",
    "        self.querysz = self.n_way * self.k_query  # number of samples per set for evaluation\n",
    "        self.resize = resize  # resize to\n",
    "        self.startidx = startidx  # index label not from 0, but from startidx\n",
    "        print('shuffle DB :%s, b:%d, %d-way, %d-shot, %d-query, resize:%d' % (\n",
    "        mode, batchsz, n_way, k_shot, k_query, resize))\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.transform = transforms.Compose([lambda x: Image.open(x).convert('RGB'),\n",
    "                                                 transforms.Resize((self.resize, self.resize)),\n",
    "                                                 # transforms.RandomHorizontalFlip(),\n",
    "                                                 # transforms.RandomRotation(5),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                                 ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([lambda x: Image.open(x).convert('RGB'),\n",
    "                                                 transforms.Resize((self.resize, self.resize)),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                                 ])\n",
    "\n",
    "        self.path = os.path.join(root, 'images')  # image path\n",
    "        csvdata = self.loadCSV(os.path.join(root, mode + '.csv'))  # csv path\n",
    "        self.data = []\n",
    "        self.img2label = {}\n",
    "        for i, (k, v) in enumerate(csvdata.items()):\n",
    "            self.data.append(v)  # [[img1, img2, ...], [img111, ...]]\n",
    "            self.img2label[k] = i + self.startidx  # {\"img_name[:9]\":label}\n",
    "        self.cls_num = len(self.data)\n",
    "\n",
    "        self.create_batch(self.batchsz)\n",
    "\n",
    "    def loadCSV(self, csvf):\n",
    "        \"\"\"\n",
    "        return a dict saving the information of csv\n",
    "        :param splitFile: csv file name\n",
    "        :return: {label:[file1, file2 ...]}\n",
    "        \"\"\"\n",
    "        dictLabels = {}\n",
    "        with open(csvf) as csvfile:\n",
    "            csvreader = csv.reader(csvfile, delimiter=',')\n",
    "            next(csvreader, None)  # skip (filename, label)\n",
    "            for i, row in enumerate(csvreader):\n",
    "                filename = row[0]\n",
    "                label = row[1]\n",
    "                # append filename to current label\n",
    "                if label in dictLabels.keys():\n",
    "                    dictLabels[label].append(filename)\n",
    "                else:\n",
    "                    dictLabels[label] = [filename]\n",
    "        return dictLabels\n",
    "\n",
    "    def create_batch(self, batchsz):\n",
    "        \"\"\"\n",
    "        create batch for meta-learning.\n",
    "        ×episode× here means batch, and it means how many sets we want to retain.\n",
    "        :param episodes: batch size\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.support_x_batch = []  # support set batch\n",
    "        self.query_x_batch = []  # query set batch\n",
    "        for b in range(batchsz):  # for each batch\n",
    "            # 1.select n_way classes randomly\n",
    "            selected_cls = np.random.choice(self.cls_num, self.n_way, False)  # no duplicate\n",
    "            np.random.shuffle(selected_cls)\n",
    "            support_x = []\n",
    "            query_x = []\n",
    "            for cls in selected_cls:\n",
    "                # 2. select k_shot + k_query for each class\n",
    "                selected_imgs_idx = np.random.choice(len(self.data[cls]), self.k_shot + self.k_query, False)\n",
    "                np.random.shuffle(selected_imgs_idx)\n",
    "                indexDtrain = np.array(selected_imgs_idx[:self.k_shot])  # idx for Dtrain\n",
    "                indexDtest = np.array(selected_imgs_idx[self.k_shot:])  # idx for Dtest\n",
    "                support_x.append(\n",
    "                    np.array(self.data[cls])[indexDtrain].tolist())  # get all images filename for current Dtrain\n",
    "                query_x.append(np.array(self.data[cls])[indexDtest].tolist())\n",
    "\n",
    "            # shuffle the correponding relation between support set and query set\n",
    "            random.shuffle(support_x)\n",
    "            random.shuffle(query_x)\n",
    "\n",
    "            self.support_x_batch.append(support_x)  # append set to current sets\n",
    "            self.query_x_batch.append(query_x)  # append sets to current sets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        index means index of sets, 0<= index <= batchsz-1\n",
    "        :param index:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # [setsz, 3, resize, resize]\n",
    "        support_x = torch.FloatTensor(self.setsz, 3, self.resize, self.resize)\n",
    "        # [setsz]\n",
    "        support_y = np.zeros((self.setsz), dtype=np.int)\n",
    "        # [querysz, 3, resize, resize]\n",
    "        query_x = torch.FloatTensor(self.querysz, 3, self.resize, self.resize)\n",
    "        # [querysz]\n",
    "        query_y = np.zeros((self.querysz), dtype=np.int)\n",
    "\n",
    "        flatten_support_x = [os.path.join(self.path, item)\n",
    "                             for sublist in self.support_x_batch[index] for item in sublist]\n",
    "        support_y = np.array(\n",
    "            [self.img2label[item[:9]]  # filename:n0153282900000005.jpg, the first 9 characters treated as label\n",
    "             for sublist in self.support_x_batch[index] for item in sublist]).astype(np.int32)\n",
    "\n",
    "        flatten_query_x = [os.path.join(self.path, item)\n",
    "                           for sublist in self.query_x_batch[index] for item in sublist]\n",
    "        query_y = np.array([self.img2label[item[:9]]\n",
    "                            for sublist in self.query_x_batch[index] for item in sublist]).astype(np.int32)\n",
    "\n",
    "        # print('global:', support_y, query_y)\n",
    "        # support_y: [setsz]\n",
    "        # query_y: [querysz]\n",
    "        # unique: [n-way], sorted\n",
    "        unique = np.unique(support_y)\n",
    "        random.shuffle(unique)\n",
    "        # relative means the label ranges from 0 to n-way\n",
    "        support_y_relative = np.zeros(self.setsz)\n",
    "        query_y_relative = np.zeros(self.querysz)\n",
    "        for idx, l in enumerate(unique):\n",
    "            support_y_relative[support_y == l] = idx\n",
    "            query_y_relative[query_y == l] = idx\n",
    "\n",
    "        # print('relative:', support_y_relative, query_y_relative)\n",
    "\n",
    "        for i, path in enumerate(flatten_support_x):\n",
    "            support_x[i] = self.transform(path)\n",
    "\n",
    "        for i, path in enumerate(flatten_query_x):\n",
    "            query_x[i] = self.transform(path)\n",
    "        # print(support_set_y)\n",
    "        # return support_x, torch.LongTensor(support_y), query_x, torch.LongTensor(query_y)\n",
    "\n",
    "        return support_x, torch.LongTensor(support_y_relative), query_x, torch.LongTensor(query_y_relative)\n",
    "\n",
    "    def __len__(self):\n",
    "        # as we have built up to batchsz of sets, you can sample some small batch size of sets.\n",
    "        return self.batchsz\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # the following episode is to view one set of images via tensorboard.\n",
    "    from torchvision.utils import make_grid\n",
    "    from matplotlib import pyplot as plt\n",
    "    from tensorboardX import SummaryWriter\n",
    "    import time\n",
    "\n",
    "    plt.ion()\n",
    "\n",
    "    tb = SummaryWriter('runs', 'mini-imagenet')\n",
    "    mini = MiniImagenet('./mini-imagenet/', mode='train', n_way=5, k_shot=1, k_query=1, batchsz=10, resize=168)\n",
    "\n",
    "    for i, set_ in enumerate(mini):\n",
    "        # support_x: [k_shot*n_way, 3, 84, 84]\n",
    "        support_x, support_y, query_x, query_y = set_\n",
    "\n",
    "        support_x = make_grid(support_x, nrow=2)\n",
    "        query_x = make_grid(query_x, nrow=2)\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.imshow(support_x.transpose(2, 0).numpy())\n",
    "        plt.pause(0.5)\n",
    "        plt.figure(2)\n",
    "        plt.imshow(query_x.transpose(2, 0).numpy())\n",
    "        plt.pause(0.5)\n",
    "\n",
    "        tb.add_image('support_x', support_x)\n",
    "        tb.add_image('query_x', query_x)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "    tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, imgc, imgsz):\n",
    "        \"\"\"\n",
    "        :param config: network config file, type:list of (string, list)\n",
    "        :param imgc: 1 or 3\n",
    "        :param imgsz:  28 or 84\n",
    "        \"\"\"\n",
    "        super(Learner, self).__init__()\n",
    "\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        # this dict contains all tensors needed to be optimized\n",
    "        self.vars = nn.ParameterList()\n",
    "        # running_mean and running_var\n",
    "        self.vars_bn = nn.ParameterList()\n",
    "\n",
    "        for i, (name, param) in enumerate(self.config):\n",
    "            if name is 'conv2d':\n",
    "                # [ch_out, ch_in, kernelsz, kernelsz]\n",
    "                w = nn.Parameter(torch.ones(*param[:4]))\n",
    "                # gain=1 according to cbfin's implementation\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                # [ch_out]\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "\n",
    "            elif name is 'convt2d':\n",
    "                # [ch_in, ch_out, kernelsz, kernelsz, stride, padding]\n",
    "                w = nn.Parameter(torch.ones(*param[:4]))\n",
    "                # gain=1 according to cbfin's implementation\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                # [ch_in, ch_out]\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[1])))\n",
    "\n",
    "            elif name is 'linear':\n",
    "                # [ch_out, ch_in]\n",
    "                w = nn.Parameter(torch.ones(*param))\n",
    "                # gain=1 according to cbfinn's implementation\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                # [ch_out]\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "\n",
    "            elif name is 'bn':\n",
    "                # [ch_out]\n",
    "                w = nn.Parameter(torch.ones(param[0]))\n",
    "                self.vars.append(w)\n",
    "                # [ch_out]\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "\n",
    "                # must set requires_grad=False\n",
    "                running_mean = nn.Parameter(torch.zeros(param[0]), requires_grad=False)\n",
    "                running_var = nn.Parameter(torch.ones(param[0]), requires_grad=False)\n",
    "                self.vars_bn.extend([running_mean, running_var])\n",
    "\n",
    "\n",
    "            elif name in ['tanh', 'relu', 'upsample', 'avg_pool2d', 'max_pool2d',\n",
    "                          'flatten', 'reshape', 'leakyrelu', 'sigmoid']:\n",
    "                continue\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "    def extra_repr(self):\n",
    "        info = ''\n",
    "\n",
    "        for name, param in self.config:\n",
    "            if name is 'conv2d':\n",
    "                tmp = 'conv2d:(ch_in:%d, ch_out:%d, k:%dx%d, stride:%d, padding:%d)'\\\n",
    "                      %(param[1], param[0], param[2], param[3], param[4], param[5],)\n",
    "                info += tmp + '\\n'\n",
    "\n",
    "            elif name is 'convt2d':\n",
    "                tmp = 'convTranspose2d:(ch_in:%d, ch_out:%d, k:%dx%d, stride:%d, padding:%d)'\\\n",
    "                      %(param[0], param[1], param[2], param[3], param[4], param[5],)\n",
    "                info += tmp + '\\n'\n",
    "\n",
    "            elif name is 'linear':\n",
    "                tmp = 'linear:(in:%d, out:%d)'%(param[1], param[0])\n",
    "                info += tmp + '\\n'\n",
    "\n",
    "            elif name is 'leakyrelu':\n",
    "                tmp = 'leakyrelu:(slope:%f)'%(param[0])\n",
    "                info += tmp + '\\n'\n",
    "\n",
    "\n",
    "            elif name is 'avg_pool2d':\n",
    "                tmp = 'avg_pool2d:(k:%d, stride:%d, padding:%d)'%(param[0], param[1], param[2])\n",
    "                info += tmp + '\\n'\n",
    "            elif name is 'max_pool2d':\n",
    "                tmp = 'max_pool2d:(k:%d, stride:%d, padding:%d)'%(param[0], param[1], param[2])\n",
    "                info += tmp + '\\n'\n",
    "            elif name in ['flatten', 'tanh', 'relu', 'upsample', 'reshape', 'sigmoid', 'use_logits', 'bn']:\n",
    "                tmp = name + ':' + str(tuple(param))\n",
    "                info += tmp + '\\n'\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        return info\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, vars=None, bn_training=True):\n",
    "        \"\"\"\n",
    "        This function can be called by finetunning, however, in finetunning, we dont wish to update\n",
    "        running_mean/running_var. Thought weights/bias of bn is updated, it has been separated by fast_weights.\n",
    "        Indeed, to not update running_mean/running_var, we need set update_bn_statistics=False\n",
    "        but weight/bias will be updated and not dirty initial theta parameters via fast_weiths.\n",
    "        :param x: [b, 1, 28, 28]\n",
    "        :param vars:\n",
    "        :param bn_training: set False to not update\n",
    "        :return: x, loss, likelihood, kld\n",
    "        \"\"\"\n",
    "\n",
    "        if vars is None:\n",
    "            vars = self.vars\n",
    "\n",
    "        idx = 0\n",
    "        bn_idx = 0\n",
    "\n",
    "        for name, param in self.config:\n",
    "            if name is 'conv2d':\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                # remember to keep synchrozied of forward_encoder and forward_decoder!\n",
    "                x = F.conv2d(x, w, b, stride=param[4], padding=param[5])\n",
    "                idx += 2\n",
    "                # print(name, param, '\\tout:', x.shape)\n",
    "            elif name is 'convt2d':\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                # remember to keep synchrozied of forward_encoder and forward_decoder!\n",
    "                x = F.conv_transpose2d(x, w, b, stride=param[4], padding=param[5])\n",
    "                idx += 2\n",
    "                # print(name, param, '\\tout:', x.shape)\n",
    "            elif name is 'linear':\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                x = F.linear(x, w, b)\n",
    "                idx += 2\n",
    "                # print('forward:', idx, x.norm().item())\n",
    "            elif name is 'bn':\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                running_mean, running_var = self.vars_bn[bn_idx], self.vars_bn[bn_idx+1]\n",
    "                x = F.batch_norm(x, running_mean, running_var, weight=w, bias=b, training=bn_training)\n",
    "                idx += 2\n",
    "                bn_idx += 2\n",
    "\n",
    "            elif name is 'flatten':\n",
    "                # print(x.shape)\n",
    "                x = x.view(x.size(0), -1)\n",
    "            elif name is 'reshape':\n",
    "                # [b, 8] => [b, 2, 2, 2]\n",
    "                x = x.view(x.size(0), *param)\n",
    "            elif name is 'relu':\n",
    "                x = F.relu(x, inplace=param[0])\n",
    "            elif name is 'leakyrelu':\n",
    "                x = F.leaky_relu(x, negative_slope=param[0], inplace=param[1])\n",
    "            elif name is 'tanh':\n",
    "                x = F.tanh(x)\n",
    "            elif name is 'sigmoid':\n",
    "                x = torch.sigmoid(x)\n",
    "            elif name is 'upsample':\n",
    "                x = F.upsample_nearest(x, scale_factor=param[0])\n",
    "            elif name is 'max_pool2d':\n",
    "                x = F.max_pool2d(x, param[0], param[1], param[2])\n",
    "            elif name is 'avg_pool2d':\n",
    "                x = F.avg_pool2d(x, param[0], param[1], param[2])\n",
    "\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        # make sure variable is used properly\n",
    "        assert idx == len(vars)\n",
    "        assert bn_idx == len(self.vars_bn)\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def zero_grad(self, vars=None):\n",
    "        \"\"\"\n",
    "        :param vars:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            if vars is None:\n",
    "                for p in self.vars:\n",
    "                    if p.grad is not None:\n",
    "                        p.grad.zero_()\n",
    "            else:\n",
    "                for p in vars:\n",
    "                    if p.grad is not None:\n",
    "                        p.grad.zero_()\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"\n",
    "        override this function since initial parameters will return with a generator.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# META"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Meta(nn.Module):\n",
    "    \"\"\"\n",
    "    Meta Learner\n",
    "    \"\"\"\n",
    "    def __init__(self, args, config):\n",
    "        \"\"\"\n",
    "        :param args:\n",
    "        \"\"\"\n",
    "        super(Meta, self).__init__()\n",
    "\n",
    "        self.update_lr = args['update_lr']\n",
    "        self.meta_lr = args['meta_lr']\n",
    "        self.n_way = args['n_way']\n",
    "        self.k_spt = args['k_spt']\n",
    "        self.k_qry = args['k_qry']\n",
    "        self.task_num = args['task_num']\n",
    "        self.update_step = args['update_step']\n",
    "        self.update_step_test = args['update_step_test']\n",
    "\n",
    "\n",
    "        self.net = Learner(config, args['imgc'], args['imgsz'])\n",
    "        self.meta_optim = optim.Adam(self.net.parameters(), lr=self.meta_lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def clip_grad_by_norm_(self, grad, max_norm):\n",
    "        \"\"\"\n",
    "        in-place gradient clipping.\n",
    "        :param grad: list of gradients\n",
    "        :param max_norm: maximum norm allowable\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        total_norm = 0\n",
    "        counter = 0\n",
    "        for g in grad:\n",
    "            param_norm = g.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "            counter += 1\n",
    "        total_norm = total_norm ** (1. / 2)\n",
    "\n",
    "        clip_coef = max_norm / (total_norm + 1e-6)\n",
    "        if clip_coef < 1:\n",
    "            for g in grad:\n",
    "                g.data.mul_(clip_coef)\n",
    "\n",
    "        return total_norm/counter\n",
    "\n",
    "\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        \"\"\"\n",
    "        :param x_spt:   [b, setsz, c_, h, w]\n",
    "        :param y_spt:   [b, setsz]\n",
    "        :param x_qry:   [b, querysz, c_, h, w]\n",
    "        :param y_qry:   [b, querysz]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        task_num, setsz, c_, h, w = x_spt.size()\n",
    "        querysz = x_qry.size(1)\n",
    "\n",
    "        losses_q = [0 for _ in range(self.update_step + 1)]  # losses_q[i] is the loss on step i\n",
    "        corrects = [0 for _ in range(self.update_step + 1)]\n",
    "\n",
    "\n",
    "        for i in range(task_num):\n",
    "\n",
    "            # 1. run the i-th task and compute loss for k=0\n",
    "            logits = self.net(x_spt[i], vars=None, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt[i])\n",
    "            grad = torch.autograd.grad(loss, self.net.parameters())\n",
    "            fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, self.net.parameters())))\n",
    "\n",
    "            # this is the loss and accuracy before first update\n",
    "            with torch.no_grad():\n",
    "                # [setsz, nway]\n",
    "                logits_q = self.net(x_qry[i], self.net.parameters(), bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[0] += loss_q\n",
    "\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[0] = corrects[0] + correct\n",
    "\n",
    "            # this is the loss and accuracy after the first update\n",
    "            with torch.no_grad():\n",
    "                # [setsz, nway]\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[1] += loss_q\n",
    "                # [setsz]\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[1] = corrects[1] + correct\n",
    "\n",
    "            for k in range(1, self.update_step):\n",
    "                # 1. run the i-th task and compute loss for k=1~K-1\n",
    "                logits = self.net(x_spt[i], fast_weights, bn_training=True)\n",
    "                loss = F.cross_entropy(logits, y_spt[i])\n",
    "                # 2. compute grad on theta_pi\n",
    "                grad = torch.autograd.grad(loss, fast_weights)\n",
    "                # 3. theta_pi = theta_pi - train_lr * grad\n",
    "                fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights)))\n",
    "\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                # loss_q will be overwritten and just keep the loss_q on last update step.\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[k + 1] += loss_q\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                    correct = torch.eq(pred_q, y_qry[i]).sum().item()  # convert to numpy\n",
    "                    corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "\n",
    "\n",
    "        # end of all tasks\n",
    "        # sum over all losses on query set across all tasks\n",
    "        loss_q = losses_q[-1] / task_num\n",
    "\n",
    "        # optimize theta parameters\n",
    "        self.meta_optim.zero_grad()\n",
    "        loss_q.backward()\n",
    "        # print('meta update')\n",
    "        # for p in self.net.parameters()[:5]:\n",
    "        # \tprint(torch.norm(p).item())\n",
    "        self.meta_optim.step()\n",
    "\n",
    "\n",
    "        accs = np.array(corrects) / (querysz * task_num)\n",
    "\n",
    "        return accs\n",
    "\n",
    "\n",
    "    def finetunning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        \"\"\"\n",
    "        :param x_spt:   [setsz, c_, h, w]\n",
    "        :param y_spt:   [setsz]\n",
    "        :param x_qry:   [querysz, c_, h, w]\n",
    "        :param y_qry:   [querysz]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert len(x_spt.shape) == 4\n",
    "\n",
    "        querysz = x_qry.size(0)\n",
    "\n",
    "        corrects = [0 for _ in range(self.update_step_test + 1)]\n",
    "\n",
    "        # in order to not ruin the state of running_mean/variance and bn_weight/bias\n",
    "        # we finetunning on the copied model instead of self.net\n",
    "        net = deepcopy(self.net)\n",
    "\n",
    "        # 1. run the i-th task and compute loss for k=0\n",
    "        logits = net(x_spt)\n",
    "        loss = F.cross_entropy(logits, y_spt)\n",
    "        grad = torch.autograd.grad(loss, net.parameters())\n",
    "        fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, net.parameters())))\n",
    "\n",
    "        # this is the loss and accuracy before first update\n",
    "        with torch.no_grad():\n",
    "            # [setsz, nway]\n",
    "            logits_q = net(x_qry, net.parameters(), bn_training=True)\n",
    "            # [setsz]\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            # scalar\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[0] = corrects[0] + correct\n",
    "\n",
    "        # this is the loss and accuracy after the first update\n",
    "        with torch.no_grad():\n",
    "            # [setsz, nway]\n",
    "            logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "            # [setsz]\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            # scalar\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[1] = corrects[1] + correct\n",
    "\n",
    "        for k in range(1, self.update_step_test):\n",
    "            # 1. run the i-th task and compute loss for k=1~K-1\n",
    "            logits = net(x_spt, fast_weights, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt)\n",
    "            # 2. compute grad on theta_pi\n",
    "            grad = torch.autograd.grad(loss, fast_weights)\n",
    "            # 3. theta_pi = theta_pi - train_lr * grad\n",
    "            fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights)))\n",
    "\n",
    "            logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "            # loss_q will be overwritten and just keep the loss_q on last update step.\n",
    "            loss_q = F.cross_entropy(logits_q, y_qry)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry).sum().item()  # convert to numpy\n",
    "                corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "\n",
    "        del net\n",
    "\n",
    "        accs = np.array(corrects) / querysz\n",
    "\n",
    "        return accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(accs, confidence=0.95):\n",
    "    n = accs.shape[0]\n",
    "    m, se = np.mean(accs), scipy.stats.sem(accs)\n",
    "    h = se * scipy.stats.t._ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, h\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    print(args)\n",
    "    torch.manual_seed(222)\n",
    "    np.random.seed(222)\n",
    "\n",
    "    config = [\n",
    "        ('conv2d', [32, 3, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 1, 0]),\n",
    "        ('flatten', []),\n",
    "        ('linear', [args['n_way'], 32 * 5 * 5])\n",
    "    ]\n",
    "\n",
    "    #device = torch.device('cuda')\n",
    "    maml = Meta(args, config)\n",
    "\n",
    "    tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "    num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "    print(maml)\n",
    "    print('Total trainable tensors:', num)\n",
    "\n",
    "    # batchsz here means total episode number\n",
    "    mini = MiniImagenet('/Users/sjadon/Desktop/github/Hands-on-One-Shot-Learning/Ch04-OptimizationBasedMethods/mini-imagenet/', mode='train', n_way=args['n_way'], k_shot=args['k_spt'],\n",
    "                        k_query=args['k_qry'],\n",
    "                        batchsz=10000, resize=args['imgsz'])\n",
    "    mini_test = MiniImagenet('/Users/sjadon/Desktop/github/Hands-on-One-Shot-Learning/Ch04-OptimizationBasedMethods/mini-imagenet/', mode='test', n_way=args['n_way'], k_shot=args['k_spt'],\n",
    "                             k_query=args['k_qry'],\n",
    "                             batchsz=100, resize=args['imgsz'])\n",
    "\n",
    "    for epoch in range(args['epoch']):\n",
    "        print (\"came here\")\n",
    "        # fetch meta_batchsz num of episode each time\n",
    "        db = DataLoader(mini, args['task_num'], shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "        for step, (x_spt, y_spt, x_qry, y_qry) in enumerate(db):\n",
    "\n",
    "            #x_spt, y_spt, x_qry, y_qry = x_spt, y_spt.to(device), x_qry.to(device), y_qry.to(device)\n",
    "\n",
    "            accs = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "            if step % 30 == 0:\n",
    "                print('step:', step, '\\ttraining acc:', accs)\n",
    "\n",
    "            if step % 500 == 0:  # evaluation\n",
    "                db_test = DataLoader(mini_test, 1, shuffle=True, num_workers=1, pin_memory=True)\n",
    "                accs_all_test = []\n",
    "\n",
    "                for x_spt, y_spt, x_qry, y_qry in db_test:\n",
    "                    x_spt, y_spt, x_qry, y_qry = x_spt.squeeze(0), y_spt.squeeze(0), \\\n",
    "                                                 x_qry.squeeze(0), y_qry.squeeze(0)\n",
    "\n",
    "                    accs = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "                    accs_all_test.append(accs)\n",
    "\n",
    "                # [b, update_step+1]\n",
    "                accs = np.array(accs_all_test).mean(axis=0).astype(np.float16)\n",
    "                print('Test acc:', accs)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args={}\n",
    "    args['epoch'],args['n_way'],args['k_spt'],args['k_qry'],args['imgsz'],args['imgc'],args['task_num'],args['meta_lr'],args['update_lr'],args['update_step'],args['update_step_test']=60,5,1,15,84,3,4,1e-3,0.01,5,10\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
