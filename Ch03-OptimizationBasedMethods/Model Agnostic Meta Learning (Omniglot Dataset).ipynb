{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Exercise: Model Adaption Meta Learning(Omniglot Dataset)\n",
    "\n",
    "In this tutorial, we will implement Model Adaption Meta Learning, to learn Omniglot classes with few examples.\n",
    "If you recall Model Agnostic Meta Learning, consists of 2 loops:\n",
    "1. To learn parameters for all tasks.\n",
    "2. To learn task specific parameters\n",
    "\n",
    "MAML algorithm aims to learn such parameters that can adapt to new tasks with very few examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"parameters.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"maml_algo.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmeta in /opt/anaconda3/envs/project09/lib/python3.6/site-packages\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from torchmeta)\n",
      "Requirement already satisfied: torch<1.5.0,>=1.4.0 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from torchmeta)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from torchmeta)\n",
      "Requirement already satisfied: h5py~=2.9.0 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from torchmeta)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from torchmeta)\n",
      "Requirement already satisfied: torchvision<0.6.0,>=0.5.0 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from torchmeta)\n",
      "Requirement already satisfied: tqdm>=4.0.0 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from torchmeta)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from requests->torchmeta)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from requests->torchmeta)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from requests->torchmeta)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from requests->torchmeta)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/project09/lib/python3.6/site-packages (from h5py~=2.9.0->torchmeta)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install torchmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmeta.modules import (MetaModule, MetaSequential, MetaConv2d,\n",
    "                               MetaBatchNorm2d, MetaLinear)\n",
    "from torchmeta.modules.utils import get_subdict\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torchmeta.datasets.helpers import omniglot\n",
    "from torchmeta.utils.data import BatchMetaDataLoader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Omniglot dataset\n",
    "\n",
    "Download Mini ImageNet Dataset: https://drive.google.com/file/d/1HkgrkAwukzEZA0TpO7010PkAOREb2Nuk/view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, **kwargs):\n",
    "    return MetaSequential(\n",
    "        MetaConv2d(in_channels, out_channels, kernel_size=3, padding=1, **kwargs),\n",
    "        MetaBatchNorm2d(out_channels, momentum=1., track_running_stats=False),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)\n",
    "    )\n",
    "\n",
    "class ConvolutionalNeuralNetwork(MetaModule):\n",
    "    def __init__(self, in_channels, out_features, hidden_size=64):\n",
    "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_features = out_features\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.features = MetaSequential(\n",
    "            conv3x3(in_channels, hidden_size),\n",
    "            conv3x3(hidden_size, hidden_size),\n",
    "            conv3x3(hidden_size, hidden_size),\n",
    "            conv3x3(hidden_size, hidden_size)\n",
    "        )\n",
    "\n",
    "        self.classifier = MetaLinear(hidden_size, out_features)\n",
    "\n",
    "    def forward(self, inputs, params=None):\n",
    "        features = self.features(inputs, params=get_subdict(params, 'features'))\n",
    "        features = features.view((features.size(0), -1))\n",
    "        logits = self.classifier(features, params=get_subdict(params, 'classifier'))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_parameters(model, loss, step_size=0.5, first_order=False):\n",
    "    grads = torch.autograd.grad(loss, model.meta_parameters(),\n",
    "        create_graph=not first_order)\n",
    "\n",
    "    params = OrderedDict()\n",
    "    for (name, param), grad in zip(model.meta_named_parameters(), grads):\n",
    "        params[name] = param - step_size * grad\n",
    "\n",
    "    return params\n",
    "\n",
    "def get_accuracy(logits, targets):\n",
    "    _, predictions = torch.max(logits, dim=-1)\n",
    "    return torch.mean(predictions.eq(targets).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip to ./omniglot/images_background.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95e56fa2e2f4ff5848b5b73e458df62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip to ./omniglot/images_evaluation.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f748cce70ab244098200453ad5c3ddb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "num_shots = 5\n",
    "num_ways = 5\n",
    "step_size = 0.4\n",
    "batch_size = 16\n",
    "num_batches = 100\n",
    "num_workers = 1\n",
    "first_order = True\n",
    "download = True\n",
    "hidden_size = 64\n",
    "output_folder = './'\n",
    "\n",
    "\n",
    "dataset = omniglot('./', shots=num_shots, ways=num_ways,\n",
    "    shuffle=True, test_shots=15, meta_train=True, download=download)\n",
    "\n",
    "\n",
    "dataloader = BatchMetaDataLoader(dataset, batch_size=batch_size,\n",
    "    shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ConvolutionalNeuralNetwork(1, num_ways,\n",
    "    hidden_size=hidden_size)\n",
    "model.to(device=device)\n",
    "model.train()\n",
    "meta_optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:50<00:00,  4.10s/it, accuracy=0.5675]\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "with tqdm(dataloader, total=num_batches) as pbar:\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        model.zero_grad()\n",
    "\n",
    "        train_inputs, train_targets = batch['train']\n",
    "        train_inputs = train_inputs.to(device=device)\n",
    "        train_targets = train_targets.to(device=device)\n",
    "\n",
    "        test_inputs, test_targets = batch['test']\n",
    "        test_inputs = test_inputs.to(device=device)\n",
    "        test_targets = test_targets.to(device=device)\n",
    "\n",
    "        outer_loss = torch.tensor(0., device=device)\n",
    "        accuracy = torch.tensor(0., device=device)\n",
    "        \n",
    "        \n",
    "        for task_idx, (train_input, train_target, test_input,\n",
    "                test_target) in enumerate(zip(train_inputs, train_targets,\n",
    "                test_inputs, test_targets)):\n",
    "            train_logit = model(train_input)\n",
    "            inner_loss = F.cross_entropy(train_logit, train_target)\n",
    "\n",
    "            model.zero_grad()\n",
    "            params = update_parameters(model, inner_loss,\n",
    "                step_size=step_size, first_order=first_order)\n",
    "\n",
    "            test_logit = model(test_input, params=params)\n",
    "            outer_loss += F.cross_entropy(test_logit, test_target)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                accuracy += get_accuracy(test_logit, test_target)\n",
    "\n",
    "        outer_loss.div_(batch_size)\n",
    "        accuracy.div_(batch_size)\n",
    "\n",
    "        outer_loss.backward()\n",
    "        meta_optimizer.step()\n",
    "\n",
    "        pbar.set_postfix(accuracy='{0:.4f}'.format(accuracy.item()))\n",
    "        if batch_idx >= num_batches:\n",
    "            break\n",
    "\n",
    "# Save model\n",
    "if output_folder is not None:\n",
    "    filename = os.path.join(output_folder, 'maml_omniglot_'\n",
    "        '{0}shot_{1}way.pt'.format(num_shots, num_ways))\n",
    "    with open(filename, 'wb') as f:\n",
    "        state_dict = model.state_dict()\n",
    "        torch.save(state_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
