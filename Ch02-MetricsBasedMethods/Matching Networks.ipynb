{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Networks Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input, Lambda\n",
    "from keras.layers.merge import Maximum\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "np.random.seed(2191)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create a Preprocessing of Omniglot Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotNShotDataset():\n",
    "    def __init__(self,batch_size,classes_per_set=5,samples_per_class=1,trainsize=1000,valsize=200):\n",
    "\n",
    "        \"\"\"\n",
    "        Constructs an N-Shot omniglot Dataset\n",
    "        :param batch_size: Experiment batch_size\n",
    "        :param classes_per_set: Integer indicating the number of classes per set\n",
    "        :param samples_per_class: Integer indicating samples per class\n",
    "        e.g. For a 20-way, 1-shot learning task, use classes_per_set=20 and samples_per_class=1\n",
    "             For a 5-way, 10-shot learning task, use classes_per_set=5 and samples_per_class=10\n",
    "        \"\"\"\n",
    "        self.x = np.load(\"./data/data.npy\")\n",
    "        self.x = np.reshape(self.x, [-1, 20, 28, 28, 1])\n",
    "        shuffle_classes = np.arange(self.x.shape[0])\n",
    "        np.random.shuffle(shuffle_classes)\n",
    "        self.x = self.x[shuffle_classes]\n",
    "        self.x_train, self.x_val  = self.x[:1200], self.x[1200:]\n",
    "        self.normalization()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = self.x.shape[0]\n",
    "        self.classes_per_set = classes_per_set\n",
    "        self.samples_per_class = samples_per_class\n",
    "\n",
    "        self.indexes = {\"train\": 0, \"val\": 0}\n",
    "        self.datasets = {\"train\": self.x_train, \"val\": self.x_val}\n",
    "        self.datasets_cache = {\"train\": self.packslice(self.datasets[\"train\"],trainsize),\n",
    "                               \"val\": self.packslice(self.datasets[\"val\"],valsize)}\n",
    "\n",
    "    def normalization(self):\n",
    "        \"\"\"\n",
    "        Normalizes our data, to have a mean of 0 and sd of 1\n",
    "        \"\"\"\n",
    "        self.mean = np.mean(self.x_train)\n",
    "        self.std = np.std(self.x_train)\n",
    "        self.max = np.max(self.x_train)\n",
    "        self.min = np.min(self.x_train)\n",
    "        print(\"train_shape\", self.x_train.shape, \"val_shape\", self.x_val.shape)\n",
    "        print(\"before_normalization\", \"mean\", self.mean, \"max\", self.max, \"min\", self.min, \"std\", self.std)\n",
    "        self.x_train = (self.x_train - self.mean) / self.std\n",
    "        self.x_val = (self.x_val - self.mean) / self.std\n",
    "        self.mean = np.mean(self.x_train)\n",
    "        self.std = np.std(self.x_train)\n",
    "        self.max = np.max(self.x_train)\n",
    "        self.min = np.min(self.x_train)\n",
    "        print(\"after_normalization\", \"mean\", self.mean, \"max\", self.max, \"min\", self.min, \"std\", self.std)\n",
    "        \n",
    "    def packslice(self, data_pack, numsamples):\n",
    "        \"\"\"\n",
    "        Collects 1000 batches data for N-shot learning\n",
    "        :param data_pack: Data pack to use (any one of train, val, test)\n",
    "        :return: A list with [support_set_x, support_set_y, target_x, target_y] ready to be fed to our networks\n",
    "        \"\"\"\n",
    "        n_samples = self.samples_per_class * self.classes_per_set\n",
    "        support_cacheX = []\n",
    "        support_cacheY = []\n",
    "        target_cacheY = []\n",
    "        \n",
    "        for iiii in range(numsamples):\n",
    "            slice_x = np.zeros((n_samples+1,28,28,1))\n",
    "            slice_y = np.zeros((n_samples,))\n",
    "            \n",
    "            ind = 0\n",
    "            pinds = np.random.permutation(n_samples)\n",
    "            classes = np.random.choice(data_pack.shape[0],self.classes_per_set,False) # chosen classes\n",
    "            \n",
    "            x_hat_class = np.random.randint(self.classes_per_set) # target class\n",
    "            \n",
    "            for j, cur_class in enumerate(classes):  # each class\n",
    "                example_inds = np.random.choice(data_pack.shape[1],self.samples_per_class,False)\n",
    "                \n",
    "                for eind in example_inds:\n",
    "                    slice_x[pinds[ind],:,:,:] = data_pack[cur_class][eind]\n",
    "                    slice_y[pinds[ind]] = j\n",
    "                    ind += 1\n",
    "                \n",
    "                if j == x_hat_class:\n",
    "                    slice_x[n_samples,:,:,:] = data_pack[cur_class][np.random.choice(data_pack.shape[1])]\n",
    "                    target_y = j\n",
    "\n",
    "            support_cacheX.append(slice_x)\n",
    "            support_cacheY.append(keras.utils.to_categorical(slice_y,self.classes_per_set))\n",
    "            target_cacheY.append(keras.utils.to_categorical(target_y,self.classes_per_set))\n",
    "            \n",
    "        return np.array(support_cacheX), np.array(support_cacheY), np.array(target_cacheY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchCosine(_Merge):\n",
    "    \"\"\"\n",
    "        Matching network with cosine similarity metric\n",
    "    \"\"\"\n",
    "    def __init__(self,nway=5,**kwargs):\n",
    "        super(MatchCosine,self).__init__(**kwargs)\n",
    "        self.eps = 1e-10\n",
    "        self.nway = nway\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if not isinstance(input_shape, list) or len(input_shape) != self.nway+2:\n",
    "            raise ValueError('A ModelCosine layer should be called on a list of inputs of length %d'%(self.nway+2))\n",
    "\n",
    "    def call(self,inputs):\n",
    "        \"\"\"\n",
    "        inputs in as array which contains the support set the embeddings, \n",
    "        the target embedding as the second last value in the array, and true class of target embedding as the last value in the array\n",
    "        \"\"\" \n",
    "        similarities = []\n",
    "\n",
    "        targetembedding = inputs[-2] # embedding of the query image\n",
    "        numsupportset = len(inputs)-2\n",
    "        for ii in range(numsupportset):\n",
    "            supportembedding = inputs[ii] # embedding for i^{th} member in the support set\n",
    "\n",
    "            sum_support = tf.reduce_sum(tf.square(supportembedding), 1, keepdims=True)\n",
    "            supportmagnitude = tf.rsqrt(tf.clip_by_value(sum_support, self.eps, float(\"inf\"))) #reciprocal of the magnitude of the member of the support \n",
    "\n",
    "            sum_query = tf.reduce_sum(tf.square(targetembedding), 1, keepdims=True)\n",
    "            querymagnitude = tf.rsqrt(tf.clip_by_value(sum_query, self.eps, float(\"inf\"))) #reciprocal of the magnitude of the query image\n",
    "\n",
    "            dot_product = tf.matmul(tf.expand_dims(targetembedding,1),tf.expand_dims(supportembedding,2))\n",
    "            dot_product = tf.squeeze(dot_product,[1])\n",
    "\n",
    "            cosine_similarity = dot_product*supportmagnitude*querymagnitude\n",
    "            similarities.append(cosine_similarity)\n",
    "\n",
    "        similarities = tf.concat(axis=1,values=similarities)\n",
    "        softmax_similarities = tf.nn.softmax(similarities)\n",
    "        preds = tf.squeeze(tf.matmul(tf.expand_dims(softmax_similarities,1),inputs[-1]))\n",
    "        \n",
    "        preds.set_shape((inputs[0].shape[0],self.nway))\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        input_shapes = input_shape\n",
    "        return (input_shapes[0][0],self.nway)\n",
    "\n",
    "\n",
    "# Siamese network like interaction\n",
    "class Siamify(_Merge):\n",
    "    def _merge_function(self,inputs):\n",
    "        return tf.negative(tf.abs(inputs[0]-inputs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape (1200, 20, 28, 28, 1) val_shape (423, 20, 28, 28, 1)\n",
      "before_normalization mean 234.2152224702381 max 255 min 0 std 56.17165918668325\n",
      "after_normalization mean -1.6715880380560316e-16 max 0.37002249587616587 min -4.169633332208283 std 1.0000000000000009\n"
     ]
    }
   ],
   "source": [
    "bsize = 32 # batch size\n",
    "classes_per_set = 5 # classes per set or 5-way\n",
    "samples_per_class = 1 # samples per class 1-short\n",
    "\n",
    "data = OmniglotNShotDataset(batch_size=bsize,classes_per_set=classes_per_set,samples_per_class=samples_per_class,trainsize=5000,valsize=1000)\n",
    "\n",
    "# Image embedding using Deep Convolutional Network\n",
    "conv1 = Conv2D(64,(3,3),padding='same',activation='relu')\n",
    "bnorm1 = BatchNormalization()\n",
    "mpool1 = MaxPooling2D((2,2),padding='same')\n",
    "conv2 = Conv2D(64,(3,3),padding='same',activation='relu')\n",
    "bnorm2 = BatchNormalization()\n",
    "mpool2 = MaxPooling2D((2,2),padding='same')\n",
    "conv3 = Conv2D(64,(3,3),padding='same',activation='relu')\n",
    "bnorm3 = BatchNormalization()\n",
    "mpool3 = MaxPooling2D((2,2),padding='same')\n",
    "conv4 = Conv2D(64,(3,3),padding='same',activation='relu')\n",
    "bnorm4 = BatchNormalization()\n",
    "mpool4 = MaxPooling2D((2,2),padding='same')\n",
    "fltn = Flatten()\n",
    "\n",
    "# Function that generarates Deep CNN embedding given the input image x\n",
    "def convembedding(x):\n",
    "    x = conv1(x)\n",
    "    x = bnorm1(x)\n",
    "    x = mpool1(x)\n",
    "    x = conv2(x)\n",
    "    x = bnorm2(x)\n",
    "    x = mpool2(x)\n",
    "    x = conv3(x)\n",
    "    x = bnorm3(x)\n",
    "    x = mpool3(x)\n",
    "    x = conv4(x)\n",
    "    x = bnorm4(x)\n",
    "    x = mpool4(x)\n",
    "    x = fltn(x)\n",
    "    \n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relational embedding comprising a 4 layer MLP\n",
    "d1 = Dense(64,activation='relu')\n",
    "dbnrm1 = BatchNormalization()\n",
    "d2 = Dense(64,activation='relu')\n",
    "dbnrm2 = BatchNormalization()\n",
    "d3 = Dense(64,activation='relu')\n",
    "dbnrm3 = BatchNormalization()\n",
    "d4 = Dense(64,activation='relu')\n",
    "dbnrm4 = BatchNormalization()\n",
    "\n",
    "def relationalembedding(x):\n",
    "    x = d1(x)\n",
    "    x = dbnrm1(x)\n",
    "    x = d2(x)\n",
    "    x = dbnrm2(x)\n",
    "    x = d3(x)\n",
    "    x = dbnrm3(x)\n",
    "    x = d4(x)\n",
    "    x = dbnrm4(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "numsupportset = samples_per_class*classes_per_set\n",
    "input1 = Input((numsupportset+1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sjadon/anaconda3/envs/mysite/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# CNN embedding support set and query image\n",
    "convolutionlayers = []\n",
    "for lidx in range(numsupportset):\n",
    "    convolutionlayers.append(convembedding(Lambda(lambda x: x[:,lidx,:,:,:])(input1)))\n",
    "targetembedding = convembedding(Lambda(lambda x: x[:,-1,:,:,:])(input1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese like pairwise interactions\n",
    "siam = Siamify()\n",
    "pairwiseinteractions = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all pairwise Siamese interactions in the support set and generate of list of interactions\n",
    "# for each member of support set \n",
    "for tt in combinations(range(numsupportset),2):\n",
    "    aa = siam([convolutionlayers[tt[0]],convolutionlayers[tt[1]]])\n",
    "    pairwiseinteractions[tt[0]].append(aa)\n",
    "    pairwiseinteractions[tt[1]].append(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Siamese interactions for query image\n",
    "targetinteractions = []\n",
    "for i in range(numsupportset):\n",
    "    aa = siam([targetembedding,convolutionlayers[i]])\n",
    "    targetinteractions.append(aa)  \n",
    "    pairwiseinteractions[i].append(aa) # add this interaction to the set of interaction for this member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 4 layer MLP transform on Max pooling of interactions to serve as Full Context Embedding (FCE)\n",
    "maxi = Maximum()\n",
    "modelinputs = []\n",
    "for i in range(numsupportset):\n",
    "    modelinputs.append(relationalembedding(maxi(pairwiseinteractions[i])))\n",
    "modelinputs.append(relationalembedding(maxi(targetinteractions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supportlabels = Input((numsupportset,classes_per_set))\n",
    "modelinputs.append(supportlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnsimilarity = MatchCosine(nway=classes_per_set)(modelinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input1,supportlabels],outputs=knnsimilarity)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sjadon/anaconda3/envs/mysite/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "5000/5000 [==============================] - 59s 12ms/step - loss: 1.5425 - acc: 0.3214 - val_loss: 1.4497 - val_acc: 0.4360\n",
      "Epoch 2/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.4440 - acc: 0.4274 - val_loss: 1.3752 - val_acc: 0.4860\n",
      "Epoch 3/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.3475 - acc: 0.4992 - val_loss: 1.2952 - val_acc: 0.5560\n",
      "Epoch 4/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.2956 - acc: 0.5340 - val_loss: 1.2660 - val_acc: 0.5560\n",
      "Epoch 5/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.2628 - acc: 0.5478 - val_loss: 1.2332 - val_acc: 0.5800\n",
      "Epoch 6/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.2374 - acc: 0.5654 - val_loss: 1.2338 - val_acc: 0.5910\n",
      "Epoch 7/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.2154 - acc: 0.5804 - val_loss: 1.2118 - val_acc: 0.6030\n",
      "Epoch 8/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.2048 - acc: 0.5874 - val_loss: 1.1964 - val_acc: 0.5840\n",
      "Epoch 9/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.1946 - acc: 0.5888 - val_loss: 1.1924 - val_acc: 0.6130\n",
      "Epoch 10/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.1836 - acc: 0.6008 - val_loss: 1.2011 - val_acc: 0.5980\n",
      "Epoch 11/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.1754 - acc: 0.6078 - val_loss: 1.1810 - val_acc: 0.6210\n",
      "Epoch 12/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.1594 - acc: 0.6252 - val_loss: 1.1851 - val_acc: 0.6450\n",
      "Epoch 13/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.1626 - acc: 0.6100 - val_loss: 1.1781 - val_acc: 0.6160\n",
      "Epoch 14/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.1491 - acc: 0.6328 - val_loss: 1.1811 - val_acc: 0.6450\n",
      "Epoch 15/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.1414 - acc: 0.6360 - val_loss: 1.1803 - val_acc: 0.6130\n",
      "Epoch 16/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.1375 - acc: 0.6382 - val_loss: 1.1628 - val_acc: 0.6350\n",
      "Epoch 17/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.1294 - acc: 0.6498 - val_loss: 1.1607 - val_acc: 0.6370\n",
      "Epoch 18/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.1250 - acc: 0.6492 - val_loss: 1.1586 - val_acc: 0.6550\n",
      "Epoch 19/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.1175 - acc: 0.6568 - val_loss: 1.1473 - val_acc: 0.6410\n",
      "Epoch 20/50\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.1119 - acc: 0.6526 - val_loss: 1.1394 - val_acc: 0.6640\n",
      "Epoch 21/50\n",
      "5000/5000 [==============================] - 55s 11ms/step - loss: 1.0939 - acc: 0.6872 - val_loss: 1.1384 - val_acc: 0.6460\n",
      "Epoch 22/50\n",
      "5000/5000 [==============================] - 57s 11ms/step - loss: 1.1001 - acc: 0.6800 - val_loss: 1.1400 - val_acc: 0.6560\n",
      "Epoch 23/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0935 - acc: 0.6808 - val_loss: 1.1530 - val_acc: 0.6630\n",
      "Epoch 24/50\n",
      "5000/5000 [==============================] - 55s 11ms/step - loss: 1.0903 - acc: 0.6924 - val_loss: 1.1392 - val_acc: 0.6600\n",
      "Epoch 25/50\n",
      "5000/5000 [==============================] - 55s 11ms/step - loss: 1.0905 - acc: 0.6846 - val_loss: 1.1443 - val_acc: 0.6500\n",
      "Epoch 26/50\n",
      "5000/5000 [==============================] - 54s 11ms/step - loss: 1.0896 - acc: 0.6996 - val_loss: 1.1236 - val_acc: 0.6700\n",
      "Epoch 27/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0842 - acc: 0.6992 - val_loss: 1.1281 - val_acc: 0.6560\n",
      "Epoch 28/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0848 - acc: 0.6904 - val_loss: 1.1230 - val_acc: 0.6590\n",
      "Epoch 29/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0695 - acc: 0.7104 - val_loss: 1.1124 - val_acc: 0.6860\n",
      "Epoch 30/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0631 - acc: 0.7212 - val_loss: 1.1392 - val_acc: 0.6570\n",
      "Epoch 31/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0553 - acc: 0.7288 - val_loss: 1.1133 - val_acc: 0.6800\n",
      "Epoch 32/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0613 - acc: 0.7118 - val_loss: 1.1230 - val_acc: 0.6780\n",
      "Epoch 33/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0500 - acc: 0.7254 - val_loss: 1.1261 - val_acc: 0.6800\n",
      "Epoch 34/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0464 - acc: 0.7340 - val_loss: 1.1238 - val_acc: 0.6670\n",
      "Epoch 35/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0399 - acc: 0.7446 - val_loss: 1.1060 - val_acc: 0.6880\n",
      "Epoch 36/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0409 - acc: 0.7388 - val_loss: 1.1213 - val_acc: 0.6760\n",
      "Epoch 37/50\n",
      "5000/5000 [==============================] - 54s 11ms/step - loss: 1.0328 - acc: 0.7468 - val_loss: 1.1270 - val_acc: 0.6700\n",
      "Epoch 38/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0398 - acc: 0.7346 - val_loss: 1.1144 - val_acc: 0.6710\n",
      "Epoch 39/50\n",
      "5000/5000 [==============================] - 54s 11ms/step - loss: 1.0278 - acc: 0.7540 - val_loss: 1.1032 - val_acc: 0.6840\n",
      "Epoch 40/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0254 - acc: 0.7556 - val_loss: 1.1132 - val_acc: 0.6730\n",
      "Epoch 41/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0270 - acc: 0.7506 - val_loss: 1.1180 - val_acc: 0.6930\n",
      "Epoch 42/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0217 - acc: 0.7572 - val_loss: 1.1319 - val_acc: 0.6700\n",
      "Epoch 43/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0142 - acc: 0.7644 - val_loss: 1.1373 - val_acc: 0.6660\n",
      "Epoch 44/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0115 - acc: 0.7692 - val_loss: 1.1200 - val_acc: 0.6740\n",
      "Epoch 45/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0045 - acc: 0.7800 - val_loss: 1.1150 - val_acc: 0.6680\n",
      "Epoch 46/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0096 - acc: 0.7726 - val_loss: 1.1133 - val_acc: 0.6630\n",
      "Epoch 47/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.0032 - acc: 0.7788 - val_loss: 1.1117 - val_acc: 0.6650\n",
      "Epoch 48/50\n",
      "5000/5000 [==============================] - 54s 11ms/step - loss: 0.9979 - acc: 0.7790 - val_loss: 1.1093 - val_acc: 0.6580\n",
      "Epoch 49/50\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 0.9931 - acc: 0.7882 - val_loss: 1.1160 - val_acc: 0.6530\n",
      "Epoch 50/50\n",
      "1376/5000 [=======>......................] - ETA: 36s - loss: 0.9896 - acc: 0.7885"
     ]
    }
   ],
   "source": [
    "history = model.fit([data.datasets_cache[\"train\"][0],data.datasets_cache[\"train\"][1]],data.datasets_cache[\"train\"][2],\n",
    "          validation_data=[[data.datasets_cache[\"val\"][0],data.datasets_cache[\"val\"][1]],data.datasets_cache[\"val\"][2]],\n",
    "          epochs=50,batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], color='b')\n",
    "plt.plot(history.history['val_loss'], color='r')\n",
    "plt.show()\n",
    "plt.plot(history.history['acc'], color='b')\n",
    "plt.plot(history.history['val_acc'], color='r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
