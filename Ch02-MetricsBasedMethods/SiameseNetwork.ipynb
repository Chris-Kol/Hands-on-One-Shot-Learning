{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network Architecture using MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- encoding: utf-8 -*-\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "class Dataset(object):\n",
    "\n",
    "    def __init__(self, x0, x1, label):\n",
    "        self.size = label.shape[0]\n",
    "        self.x0 = torch.from_numpy(x0)\n",
    "        self.x1 = torch.from_numpy(x1)\n",
    "        self.label = torch.from_numpy(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x0[index],\n",
    "                self.x1[index],\n",
    "                self.label[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "def create_pairs(data, digit_indices):\n",
    "    x0_data = []\n",
    "    x1_data = []\n",
    "    label = []\n",
    "    n = min([len(digit_indices[d]) for d in range(10)]) - 1\n",
    "    for d in range(10):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            x0_data.append(data[z1] / 255.)\n",
    "            x1_data.append(data[z2] / 255.)\n",
    "            label.append(1)\n",
    "            inc = random.randrange(1, 10)\n",
    "            dn = (d + inc) % 10\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            x0_data.append(data[z1] / 255.)\n",
    "            x1_data.append(data[z2] / 255.)\n",
    "            label.append(0)\n",
    "\n",
    "    x0_data = np.array(x0_data, dtype=np.float32)\n",
    "    x0_data = x0_data.reshape([-1, 1, 28, 28])\n",
    "    x1_data = np.array(x1_data, dtype=np.float32)\n",
    "    x1_data = x1_data.reshape([-1, 1, 28, 28])\n",
    "    label = np.array(label, dtype=np.int32)\n",
    "    return x0_data, x1_data, label\n",
    "\n",
    "\n",
    "def create_iterator(data, label, batchsize, shuffle=False):\n",
    "    digit_indices = [np.where(label == i)[0] for i in range(10)]\n",
    "    x0, x1, label = create_pairs(data, digit_indices)\n",
    "    ret = Dataset(x0, x1, label)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function: Contrastive Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_function(x0, x1, y, margin=1.0):\n",
    "    # euclidian distance\n",
    "    diff = x0 - x1\n",
    "    dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
    "    dist = torch.sqrt(dist_sq)\n",
    "\n",
    "    mdist = margin - dist\n",
    "    dist = torch.clamp(mdist, min=0.0)\n",
    "    loss = y * dist_sq + (1 - y) * torch.pow(dist, 2)\n",
    "    loss = torch.sum(loss) / 2.0 / x0.size()[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Siamese Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self,flag_kaf=False):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 20, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(20, 50, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(50 * 4 * 4, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(500,10),\n",
    "            nn.Linear(10, 2))\n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist(numpy_all, numpy_labels,name=\"../Results/embeddings_plot.png\"):\n",
    "        c = ['#ff0000', '#ffff00', '#00ff00', '#00ffff', '#0000ff',\n",
    "             '#ff00ff', '#990000', '#999900', '#009900', '#009999']\n",
    "\n",
    "        for i in range(10):\n",
    "            f = numpy_all[np.where(numpy_labels == i)]\n",
    "            plt.plot(f[:, 0], f[:, 1], '.', c=c[i])\n",
    "        plt.legend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "        plt.savefig(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6777 2728 2450 3831 7634 2781 9646 7808 5046 4164 4562 3852 9155 4061\n",
      "  892 8571 7961 5447 6580 2515 9190 3000 4702 3074 7142 1333 2360 7539\n",
      " 5780 5950 5288 2067 8508 9892 4355 3902 5688 3811 6022 2502 2938 1183\n",
      " 6950 8907 3684 8932 9286 6204 9559 3134]\n"
     ]
    }
   ],
   "source": [
    "batchsize=8\n",
    "train = dsets.MNIST(root='../data/',train=True,download=True)\n",
    "test = dsets.MNIST(root='../data/',train=False,transform=transforms.Compose([transforms.ToTensor(),]))\n",
    "indices= np.random.choice(len(train.train_labels.numpy()), 500, replace=False)\n",
    "indices_test= np.random.choice(len(test.test_labels.numpy()), 50, replace=False)\n",
    "print (indices_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = create_iterator(train.train_data.numpy()[indices],train.train_labels.numpy()[indices],batchsize)\n",
    "test_iter = create_iterator(test.test_data.numpy()[indices_test],test.test_labels.numpy()[indices_test],batchsize)\n",
    "# model\n",
    "model = SiameseNetwork()\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "# Loss and Optimizer\n",
    "criterion = contrastive_loss_function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=momentum)\n",
    "#kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "kwargs = {}\n",
    "train_loader = torch.utils.data.DataLoader(train_iter,batch_size=batchsize, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_iter,batch_size=batchsize, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:0------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.182743\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.294567\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.264909\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.191437\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.085343\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.081894\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.142088\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.056993\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.059235\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.111203\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.101546\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.101908\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.047335\n",
      "Train Epoch:1------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.136001\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.086304\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.077194\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.077295\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.066750\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.169665\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.091509\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.023729\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.063292\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.130668\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.065986\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.067026\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.084928\n",
      "Train Epoch:2------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.079085\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.041590\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.123802\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.088762\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.055473\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.038250\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.071856\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.036717\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.056959\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.075289\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.106019\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.084632\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.034346\n",
      "Train Epoch:3------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.074333\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.024023\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.040055\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.097390\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.070316\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.044102\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.115080\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.061282\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.078480\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.102780\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.022780\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.021272\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.071711\n",
      "Train Epoch:4------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.039084\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.096034\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.030032\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.021254\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.063931\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.030809\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.071825\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.036886\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.054757\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.069393\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.046184\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.023962\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.028470\n",
      "Train Epoch:5------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.058541\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.033619\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.022271\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.035231\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.059164\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.017659\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.093436\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.046961\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.090326\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.049340\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.035903\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.033132\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.040546\n",
      "Train Epoch:6------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.027375\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.039327\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.061324\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.028565\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.017909\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.021139\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.013468\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.025237\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.033724\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.067560\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.016977\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.041135\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.068213\n",
      "Train Epoch:7------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.017375\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.023295\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.030063\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.014970\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.014371\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.028818\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.033732\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.024352\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.009999\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.013909\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.034805\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.018870\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.033151\n",
      "Train Epoch:8------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.060787\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.007946\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.041955\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.024979\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.026821\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.044016\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.008788\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.019685\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.071913\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.037657\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.008523\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.052369\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.025856\n",
      "Train Epoch:9------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.009846\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.004237\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.013789\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.013590\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.015793\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.003809\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.008783\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.012272\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.012353\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.006357\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.023627\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.023112\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.036203\n",
      "Train Epoch:10------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.013020\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.027654\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.013108\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.005002\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.017943\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.057500\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.003217\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.009930\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.011757\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.012454\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.011731\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.025949\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.019395\n",
      "Train Epoch:11------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.025953\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.017437\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.014927\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.013809\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.003445\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.004070\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.024300\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.002538\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.006870\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.045908\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.031045\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.023824\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.039723\n",
      "Train Epoch:12------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.019816\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.023992\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.031399\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.034396\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.009662\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.010083\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.010647\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.013777\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.007685\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.004732\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.011279\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.014806\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.012114\n",
      "Train Epoch:13------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.008592\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.013741\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.005662\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.010847\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.004101\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.003107\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.027296\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.020207\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.017217\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.011652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.002170\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.005284\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.027830\n",
      "Train Epoch:14------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.003901\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.001776\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.001504\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.010764\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.001290\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.004665\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.002914\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.004263\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.007383\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.012963\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.002089\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.027647\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.005878\n",
      "Train Epoch:15------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.006402\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.006410\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.010475\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.014961\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.002799\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.011134\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.007328\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.010707\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.006968\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.012340\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.006274\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.018383\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.007215\n",
      "Train Epoch:16------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.015812\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.004850\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000000\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.012181\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.003888\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.014521\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.011306\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.010880\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.007151\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.008606\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.002297\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.009675\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.004501\n",
      "Train Epoch:17------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.006141\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.008562\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.001147\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.008251\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.005973\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.005377\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.011269\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.004322\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.016088\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.004652\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.003253\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.007907\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.007220\n",
      "Train Epoch:18------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.012578\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.015648\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.005365\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.006652\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.002125\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.002021\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.002532\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.007832\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000215\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.006641\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001580\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.005157\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.004808\n",
      "Train Epoch:19------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000923\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.002109\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.005645\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.015374\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.010398\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.004380\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.004594\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.005870\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.005965\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.003577\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000841\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.005660\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.006647\n",
      "Train Epoch:20------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001579\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.006923\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.003264\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.004628\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.004058\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.008302\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.012375\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.023954\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001809\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.001813\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.003245\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.005276\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.002010\n",
      "Train Epoch:21------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.002217\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.001085\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.026897\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.002084\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.013509\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.002148\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.002710\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.001928\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001376\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.008644\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.012177\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.016341\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.010975\n",
      "Train Epoch:22------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.005039\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.005065\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000867\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.001324\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.010168\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.005671\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.006925\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.006212\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.002048\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.002216\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.017376\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.005109\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.008112\n",
      "Train Epoch:23------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.002071\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.004334\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.004381\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.002221\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.004931\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.003658\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.007299\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.011781\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.005461\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.004110\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.010813\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.004345\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000562\n",
      "Train Epoch:24------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.005428\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.001690\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.002303\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.004864\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.003257\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.002842\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.001281\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000901\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.003084\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.002355\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001658\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.003583\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000899\n",
      "Train Epoch:25------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001828\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.003213\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000589\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000219\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.001129\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.002981\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.001866\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.002648\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.005979\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.002339\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001740\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000301\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.010330\n",
      "Train Epoch:26------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.006902\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.001765\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.002842\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.001669\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.001629\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.005683\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.003354\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.002224\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.007592\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.003175\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.003754\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.002741\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.003867\n",
      "Train Epoch:27------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001908\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.003214\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.006428\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.001044\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.003578\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.006496\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.003117\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.006479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.007121\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.006472\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.002164\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001963\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.011654\n",
      "Train Epoch:28------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001293\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000432\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.002103\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.001419\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.002628\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.002246\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000791\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.002954\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.002450\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.002797\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.007178\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.010951\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.004288\n",
      "Train Epoch:29------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001439\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.006686\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000400\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000468\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.002711\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.004058\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000806\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.004051\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.003356\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.006741\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001400\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.008668\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.006672\n",
      "Train Epoch:30------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001898\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.003637\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.002042\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.002022\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.002093\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.001256\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.004464\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000368\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.002659\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.002203\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000802\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.007874\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.003093\n",
      "Train Epoch:31------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001309\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000940\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.001729\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000535\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000626\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.002169\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.002339\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000000\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.012304\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.006654\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001457\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.004810\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001659\n",
      "Train Epoch:32------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000770\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.002820\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.001465\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000846\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.005273\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.002866\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.003063\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000675\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001917\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.007222\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.002288\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000251\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.003955\n",
      "Train Epoch:33------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.002214\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000911\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.004261\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.002172\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.003375\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000432\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.003182\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.002445\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000166\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.004092\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.009606\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001315\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.002727\n",
      "Train Epoch:34------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000527\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000642\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.002767\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000254\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.001773\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.004944\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.004215\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.003775\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000564\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.002274\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.002979\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000472\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.002631\n",
      "Train Epoch:35------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000740\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.003220\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000696\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.001130\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.001310\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.003084\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.004068\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000736\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001014\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000367\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001316\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.002693\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000336\n",
      "Train Epoch:36------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001124\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.001432\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.002120\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000927\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.001159\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.003274\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.003841\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.002422\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001521\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.002790\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000983\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001337\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001675\n",
      "Train Epoch:37------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000827\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.001678\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000782\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000429\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.002658\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.001700\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000772\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000403\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001145\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.004029\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000410\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001930\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001339\n",
      "Train Epoch:38------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000964\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.001377\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000992\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000645\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.001646\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000413\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.001231\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000922\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.003317\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.001630\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000947\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.006824\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001292\n",
      "Train Epoch:39------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001242\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000783\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000589\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000375\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.004759\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000370\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.003304\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000271\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.002618\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000580\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001757\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000980\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.002124\n",
      "Train Epoch:40------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001439\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000724\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000202\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000980\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000454\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.001241\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.001721\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000717\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000431\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.001128\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.002699\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000749\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001208\n",
      "Train Epoch:41------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001624\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000809\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.001273\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.001167\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000398\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.001339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.002190\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000947\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001117\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000863\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001207\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.002571\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001423\n",
      "Train Epoch:42------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000587\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000639\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.002768\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000645\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000592\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.002884\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.001722\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.002319\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001073\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000572\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001763\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000569\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000332\n",
      "Train Epoch:43------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000238\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000099\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.002948\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000362\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.002537\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000306\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.001435\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.001012\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001776\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000080\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001387\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000909\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000912\n",
      "Train Epoch:44------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000471\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000576\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000841\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000923\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000447\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000464\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.001001\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.001861\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.002400\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.002552\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001208\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001314\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001538\n",
      "Train Epoch:45------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000683\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.001534\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.001478\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000655\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000654\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.002180\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.003646\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000473\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000849\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.001207\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001745\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000697\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.002334\n",
      "Train Epoch:46------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001042\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.001578\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000865\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.001509\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000582\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000106\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.002265\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000408\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001134\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000106\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001639\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001392\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.002352\n",
      "Train Epoch:47------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000393\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000558\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.001132\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000933\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000449\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.002138\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000787\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.001096\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000783\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000548\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001333\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000858\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000319\n",
      "Train Epoch:48------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000214\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000259\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000508\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000371\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.001514\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.003074\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000989\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.001310\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.002150\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.002363\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000082\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000347\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001129\n",
      "Train Epoch:49------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001128\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000918\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000395\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000288\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000706\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000625\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000593\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000162\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.003298\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.001007\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001485\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000185\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001255\n",
      "Train Epoch:50------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000766\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000522\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.001057\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000691\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000621\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.003811\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.001756\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000686\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.002074\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000602\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000865\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000051\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001489\n",
      "Train Epoch:51------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001407\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.002899\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000407\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000595\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000420\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000494\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000904\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000787\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000417\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.002126\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000957\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000524\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000114\n",
      "Train Epoch:52------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000626\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000510\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000948\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000386\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.001283\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000013\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000302\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.001713\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000452\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000539\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000801\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000209\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001588\n",
      "Train Epoch:53------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000482\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000828\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000000\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000629\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.002016\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000881\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.001268\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000908\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000325\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000602\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000515\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000405\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000857\n",
      "Train Epoch:54------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001075\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000980\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000333\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000742\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.001221\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000109\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000112\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000059\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000636\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.001453\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000904\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000339\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000326\n",
      "Train Epoch:55------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000437\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.001137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000459\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.001223\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000336\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.002201\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000640\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000832\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001355\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.001039\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000551\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001010\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000978\n",
      "Train Epoch:56------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000232\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000121\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000471\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000290\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000237\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000510\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000065\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000606\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000280\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000159\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000573\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000891\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001129\n",
      "Train Epoch:57------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000892\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000121\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000219\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000230\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000391\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000244\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.001033\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000453\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000186\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.003128\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001189\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001479\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000599\n",
      "Train Epoch:58------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000045\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.001406\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000821\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000137\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000686\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000609\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.001249\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000169\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000210\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000376\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000139\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001948\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001184\n",
      "Train Epoch:59------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000478\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000205\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000684\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000933\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000254\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000200\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000247\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000338\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000190\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000490\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001107\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001158\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000380\n",
      "Train Epoch:60------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000358\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000122\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000954\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.001047\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000155\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000475\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000145\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000562\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000101\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000297\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000673\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000545\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000829\n",
      "Train Epoch:61------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000396\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000269\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000532\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000530\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000291\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000595\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000699\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000352\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001089\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.001085\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000741\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000002\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000352\n",
      "Train Epoch:62------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000136\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000466\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000251\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000558\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000313\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000278\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.001210\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000381\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000305\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000393\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000373\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000922\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000356\n",
      "Train Epoch:63------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000201\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000513\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.001963\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000529\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000614\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000171\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000546\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000523\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000155\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000245\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000277\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000321\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000768\n",
      "Train Epoch:64------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000250\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000113\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000191\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000505\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000292\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000762\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000334\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000570\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000448\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.001335\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000601\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000276\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000210\n",
      "Train Epoch:65------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000177\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000718\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000088\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000288\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000435\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000976\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000794\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000468\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000030\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000558\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.001164\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000029\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000089\n",
      "Train Epoch:66------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000051\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000304\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000380\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000263\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000533\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000052\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000208\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000369\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000248\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000185\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000444\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001053\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000685\n",
      "Train Epoch:67------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000208\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000101\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000155\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000613\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000422\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000585\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000396\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000220\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000193\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000593\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000215\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000146\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000154\n",
      "Train Epoch:68------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000389\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000457\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000206\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000179\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000228\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000423\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000227\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000212\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000513\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000146\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000957\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000362\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:69------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000409\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000068\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000157\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000216\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000026\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000832\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000613\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000535\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000234\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000393\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000237\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000596\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000028\n",
      "Train Epoch:70------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001589\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000293\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.001147\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000264\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000103\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000350\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000705\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000533\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000531\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000261\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000258\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000514\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000164\n",
      "Train Epoch:71------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000485\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000144\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000384\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000252\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000262\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000339\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000493\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.001675\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000367\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000622\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000267\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001566\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000221\n",
      "Train Epoch:72------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000149\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000727\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000067\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000764\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000269\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000235\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000388\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000317\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000896\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000377\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000463\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000271\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000335\n",
      "Train Epoch:73------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.001098\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000100\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000816\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000092\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000605\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000303\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000045\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000035\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000255\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000137\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000118\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000166\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000617\n",
      "Train Epoch:74------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000183\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000270\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000565\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000378\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000152\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000450\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000188\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000523\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000284\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000515\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000337\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000242\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000018\n",
      "Train Epoch:75------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000458\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000279\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000518\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000206\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000940\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000017\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000166\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000222\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000156\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000299\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000221\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000652\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000412\n",
      "Train Epoch:76------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000378\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000176\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000374\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000211\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000487\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000624\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000882\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000152\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000431\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000427\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000192\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000693\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000552\n",
      "Train Epoch:77------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000535\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000161\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000195\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000080\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000407\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000311\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000127\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000119\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000213\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000143\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000588\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000440\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000901\n",
      "Train Epoch:78------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000359\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000590\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000147\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000848\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000353\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000141\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000074\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000761\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000078\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000194\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000169\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000052\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000706\n",
      "Train Epoch:79------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000077\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000486\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000150\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000339\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000099\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000375\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000377\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000476\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000031\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000753\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000305\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000451\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000018\n",
      "Train Epoch:80------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000559\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000518\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000129\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000181\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.001623\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000064\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000033\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000194\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000200\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000441\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000056\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000736\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000150\n",
      "Train Epoch:81------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000137\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000502\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000540\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000291\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000954\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000177\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000119\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000014\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000487\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000043\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000490\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000259\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.001253\n",
      "Train Epoch:82------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000603\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000240\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000184\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000098\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000207\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000167\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000213\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000166\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000459\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000118\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000651\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000315\n",
      "Train Epoch:83------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000068\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000328\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000094\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000473\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000206\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000266\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000574\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000304\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000272\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000209\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000015\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000108\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000646\n",
      "Train Epoch:84------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000192\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000162\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000275\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000380\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000111\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000378\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000302\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000205\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000318\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000175\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000342\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000116\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000437\n",
      "Train Epoch:85------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000222\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000117\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000103\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000444\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000301\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000249\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000137\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000045\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000469\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000301\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000051\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000249\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000141\n",
      "Train Epoch:86------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000506\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000512\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000212\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000417\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000347\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000111\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000048\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000587\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000204\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000227\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000214\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000127\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000359\n",
      "Train Epoch:87------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000035\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000229\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000067\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000184\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000026\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000020\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000336\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000681\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000155\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000227\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000202\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001860\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000404\n",
      "Train Epoch:88------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000068\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000298\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000313\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000080\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000143\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000171\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000434\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000125\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000135\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000050\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000297\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001161\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000211\n",
      "Train Epoch:89------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000507\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000130\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000247\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000101\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000049\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.001323\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000084\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000475\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000151\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000272\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000407\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000307\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000198\n",
      "Train Epoch:90------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000132\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000082\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000325\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000094\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000150\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000358\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000253\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000125\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000043\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000086\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000010\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000182\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000304\n",
      "Train Epoch:91------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000117\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000157\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000167\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000289\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000034\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000287\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000016\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000140\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.001049\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.001102\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000209\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000240\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000463\n",
      "Train Epoch:92------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000099\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000055\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000241\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000162\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000050\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000137\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000163\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000079\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000167\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000164\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000991\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000117\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000356\n",
      "Train Epoch:93------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000062\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000148\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000136\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000161\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000056\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000256\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000740\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000912\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000073\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000177\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000783\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000206\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000205\n",
      "Train Epoch:94------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000042\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000222\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000044\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000091\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000495\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000095\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000024\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000236\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000134\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000233\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000000\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000174\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000117\n",
      "Train Epoch:95------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000071\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000150\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000112\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000194\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000589\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000238\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000095\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000174\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000030\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000343\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000102\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000144\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000393\n",
      "Train Epoch:96------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000198\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000110\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000147\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000217\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000119\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000056\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000403\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000229\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000166\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000038\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000385\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000348\n",
      "Train Epoch:97------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000107\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000059\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000194\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000050\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000126\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000271\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000205\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000054\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000111\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000254\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000216\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000153\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000289\n",
      "Train Epoch:98------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000350\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000172\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000009\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000065\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000081\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000252\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000013\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000183\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000159\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000056\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000373\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.001200\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000497\n",
      "Train Epoch:99------------------\n",
      "Batch id: 0 [0/820 (0%)]\tLoss: 0.000078\n",
      "Batch id: 8 [64/820 (8%)]\tLoss: 0.000146\n",
      "Batch id: 16 [128/820 (16%)]\tLoss: 0.000477\n",
      "Batch id: 24 [192/820 (23%)]\tLoss: 0.000077\n",
      "Batch id: 32 [256/820 (31%)]\tLoss: 0.000094\n",
      "Batch id: 40 [320/820 (39%)]\tLoss: 0.000044\n",
      "Batch id: 48 [384/820 (47%)]\tLoss: 0.000129\n",
      "Batch id: 56 [448/820 (54%)]\tLoss: 0.000220\n",
      "Batch id: 64 [512/820 (62%)]\tLoss: 0.000076\n",
      "Batch id: 72 [576/820 (70%)]\tLoss: 0.000179\n",
      "Batch id: 80 [640/820 (78%)]\tLoss: 0.000091\n",
      "Batch id: 88 [704/820 (85%)]\tLoss: 0.000330\n",
      "Batch id: 96 [768/820 (93%)]\tLoss: 0.000070\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "running_loss=0.0\n",
    "epochs =100\n",
    "for epoch in range(epochs):\n",
    "    print('Train Epoch:'+str(epoch)+\"------------------\")\n",
    "    for batch_idx, (x0, x1, labels) in enumerate(train_loader):\n",
    "        labels = labels.float()\n",
    "        x0, x1, labels = Variable(x0), Variable(x1), Variable(labels)\n",
    "        output1, output2 = model(x0, x1)\n",
    "        loss = criterion(output1, output2, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        if batch_idx % batchsize == 0:\n",
    "            print('Batch id: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                batch_idx, batch_idx * len(labels), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    torch.save(model.state_dict(), './model-epoch-%s.pth' % epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(train_loss,name=\"train_loss.png\"):\n",
    "    plt.plot(train_loss, label=\"train loss\")\n",
    "    plt.legend()\n",
    "plot_loss(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def test_model(model):\n",
    "        model.eval()\n",
    "        all_ = []\n",
    "        all_labels = []\n",
    "        #original_labels=[]\n",
    "        for batch_idx, (x0, x1, labels) in enumerate(test_loader):\n",
    "            labels = labels.float()\n",
    "            x0, x1, labels = Variable(x0), Variable(x1), Variable(labels)\n",
    "            output1, output2 = model(x0, x1)\n",
    "            similarity=cosine_similarity(output1.detach().numpy(), output2.detach().numpy())\n",
    "            print (\"label: {}\".format(labels))\n",
    "            print (\"similarity: {}\".format(similarity))\n",
    "            \n",
    "def testing_plots(name_file,model):\n",
    "        filehandler = open(name_file,\"wb\")\n",
    "        dict_pickle={}\n",
    "        numpy_all, numpy_labels = test_model(model)\n",
    "        dict_pickle[\"numpy_all\"]=numpy_all\n",
    "        dict_pickle[\"numpy_labels\"]=numpy_labels\n",
    "        pickle.dump(dict_pickle,filehandler)\n",
    "        plot_mnist(numpy_all, numpy_labels)\n",
    "        filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: tensor([0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "similarity: [[ 0.3298342  -0.98003775 -0.5197776   0.9806874  -0.17391077  1.\n",
      "  -0.9457348   0.9806875 ]\n",
      " [-0.92817706  0.15434137 -0.8769077   0.23967853  0.975901    0.0451692\n",
      "   0.2818901   0.23967865]\n",
      " [-0.9991715   0.4755301  -0.6659634  -0.09841147  0.9927341  -0.29114276\n",
      "   0.58620715 -0.09841141]\n",
      " [-0.19260639  0.94193286  0.6356891  -0.9985129   0.03248349 -0.98989093\n",
      "   0.89008784 -0.998513  ]\n",
      " [ 0.13882792 -0.9222268  -0.6768248   0.9999998   0.0220488   0.9806874\n",
      "  -0.86391795  0.99999994]\n",
      " [-0.9870149   0.3662213  -0.75088847  0.0220488   1.0000002  -0.17391077\n",
      "   0.48446172  0.02204892]\n",
      " [-0.7769365   0.9381627  -0.00706653 -0.7313429   0.66571885 -0.8506073\n",
      "   0.97530264 -0.7313429 ]\n",
      " [-0.7769365   0.9381627  -0.00706653 -0.7313429   0.66571885 -0.8506073\n",
      "   0.97530264 -0.7313429 ]]\n",
      "label: tensor([1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "similarity: [[ 0.98977745 -0.9748548  -0.9991715  -0.16617358 -0.7793565   0.38362318\n",
      "  -0.92817694  0.32983428]\n",
      " [-0.954016    0.9264014   0.9927341   0.00561965  0.66858906 -0.5269815\n",
      "   0.9759009  -0.17391083]\n",
      " [-0.86561406  0.82191014  0.9425525  -0.2127265   0.4902056  -0.69973683\n",
      "   1.          0.04516909]\n",
      " [ 0.46110183 -0.531911   -0.29114276 -0.9857232  -0.84857506 -0.7452782\n",
      "   0.04516926  1.        ]\n",
      " [-0.9377301   0.96292853  0.85844046  0.6169146   0.9839706   0.10396349\n",
      "   0.63778234 -0.74062234]\n",
      " [ 0.5183918  -0.44694746 -0.6659634   0.65619904 -0.01091936  0.9569877\n",
      "  -0.87690765 -0.5197775 ]\n",
      " [ 0.98977745 -0.9748548  -0.9991716  -0.16617355 -0.7793565   0.38362324\n",
      "  -0.928177    0.32983422]\n",
      " [-0.9377301   0.96292853  0.85844046  0.6169146   0.9839706   0.1039635\n",
      "   0.63778234 -0.7406224 ]]\n",
      "label: tensor([1., 1., 1., 0.])\n",
      "similarity: [[ 0.9983797   0.13490444 -0.99772215 -0.09841147]\n",
      " [-0.15487671  0.97277254  0.03105944  0.9999999 ]\n",
      " [-0.9999971  -0.0806894   0.99256146  0.15251327]\n",
      " [-0.633841   -0.82072145  0.72494    -0.6659634 ]]\n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
